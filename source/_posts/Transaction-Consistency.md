---
title: 分布式事务解决方案 & 一致性协议
author: DragonBaby308
avatar: 'https://cdn.jsdelivr.net/gh/DragonBaby308/cdn@1.2/img/header/avatar.jpg'
authorLink: www.dragonbaby308.com
authorAbout: 气是清风肉是泥。
authorDesc: 佯狂难免假成真。
categories: 分布式
comments: true
photos: https://cdn.jsdelivr.net/gh/DragonBaby308/cdn@1.3.1/img/posts/db3/Transaction.png
date: 2019-12-17 20:47:23
tags:
- 分布式
- 2PC
- XA
- 3PC
- Paxos
- ZooKeeper
- ZAB
- Raft
- CAP
- 高可用
- Quorum
- TCC
- MQ
- 幂等性
keywords:
description:
---

#  分布式事务解决方案 & 一致性协议


---

##  （一）分布式事务

分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。

---

###  1.特性

1. `A`：原子性。事务操作要么全部完成，要么全部不完成，不存在只完成部分的中间状态。
2. `C`：一致性。
3. `I`：隔离性。事务与事务之间不会相互影响，一个事务的中间状态不会被其他事务感知。
4. `D`：持久性。一旦事务完成，其对数据做出的更改就保存在了数据库中。

---

###  2.解决方案

####  （1）`TCC`：补偿型事务解决方案

`TCC`指的是`Try`（尝试）、`Confirm`（确认）、`Cancel`（取消）。其核心思想是：**针对每一个操作，都需要注册一个与其相对应的确认和取消操作**。
1. `Try`：对业务系统做检测及资源预留  ——  类似于`2PC`的`Precommit`准备阶段。
2. `Confirm`：对业务系统做确认提交  ——  类似于`2PC`的`Commit`提交阶段。
3. `Cancel`：在业务执行错误时，需要回滚的状态下，**取消业务，释放预留资源**。

> 比如A向B转账：  
1.在`Try`阶段，首先将A和B的钱冻结起来。  
2.在`Confirm`阶段，转账，转账成功则解冻两个账户。  
3.如果第2步执行失败，在`Cancel`阶段，将两个账户解冻。

* 优点：和`2PC`相比，流程简单
* 缺点：数据一致性弱于`2PC`，且在第2/3步都可能失败

---

####  （2）基于可靠消息的最终一致性解决方案

> 如：订单系统创建订单成功后，库存系统需要扣减相应库存。

#####  订单系统

1. 创建订单前，**创建预发送消息，保存到消息表中，此时消息状态为：未发送**
2. 创建订单，如果**失败**则将消息表预发消息**删除**
3. 创建订单**成功**，修改消息表消息状态为：**发送中，并将消息发送至**[`MQ`](http://www.dragonbaby308.com/mq/)
4. **消息发送失败，则订单回滚，在消息表中删除对应消息**；发送成功则OK

#####  库存系统

1. 从[`MQ`](http://www.dragonbaby308.com/mq/)监听并消费消息，**同时根据消息`ID`查询消息是否被消费，保证幂等性**
2. **如果消息未被消费（消息表中存在此消息），则库存系统扣减库存；如果消息已经被消费（消息表中无此消息），则不做处理**
3. **库存系统扣减库存成功，则删除消息表中消息；失败则不做处理**
4. **定时任务会定时扫描消息表中超时未被消费的消息，然后尝试重发，如果超过最大重试次数后仍未被消费，则记录日志通知人工补偿**

---

##  （二）一致性协议

###  1.`2PC`（也称`XA`）

![](https://dragonbaby308.oss-cn-hangzhou.aliyuncs.com/DS/2pc.jpg)

`2PC`即二阶段提交协议，在数据库中的应用即`XA`协议：
1. 第一阶段（准备阶段，`Precommit`）：**事务协调器要求每个事务参与者锁定资源、执行事务，但是不提交事务，而是只反映是否可以提交**；
2. 第二阶段（提交阶段，`Commit`/`Rollback`）：**①如果所有事务参与者反映可以提交，则提交事务，释放锁定的资源；②如果有事务参与者反馈不可提交，则回滚事务，同样释放锁定资源**

####  2PC的特点

1. 强一致性：**牺牲了部分可用性，换取数据的强一致性**；
2. 先斩后奏：**先锁定资源、执行事务，再根据反馈决定提交还是回滚**

####  2PC的缺点

1. 阻塞：**任何一次指令必须收到明确的响应才会执行下一步，否则一直处于阻塞状态，锁住的资源也不会释放**
> `3PC`引入**超时机制**解决了阻塞问题。

2. 单点问题：**一旦协调者宕机，参与者没有协调者指挥，会一直阻塞**
3. 脑裂：**协调者二阶段发送`Commit`，有的节点收到了消息提交了事务，有的节点没有收到就没有提交事务，多个参与者之间数据不一致**

---

###  2.`3PC`

![](https://dragonbaby308.oss-cn-hangzhou.aliyuncs.com/DS/3PC.jpg)

3PC即三阶段提交协议：
1. 询问阶段：**协调者询问事务参与者是否可以执行事务，参与者只需要回答Yes/No，不需要真正执行**
> **询问阶段 超时 导致中止！**

2. 准备阶段：**①如果所有事务参与者反馈可以执行事务，协调者向所有参与者发送执行请求，参与者锁定资源、执行事务，但是不提交，只反馈是否可以提交；②如果有事务参与者反馈不可用执行、或是超时没有收到某些事务参与者的反馈，那么协调者向参与者发送中止事务请求**
> **准备阶段相当于2PC的`PreCommit`阶段，这阶段 超时 默认成功！**

3. 提交阶段：**①如果所有事务参与者反映可以提交、或是超时没有收到某些参与者的反馈，则默认执行成功、提交事务，释放锁定的资源；②如果有事务参与者反馈不可提交，则回滚事务，同样释放锁定资源**
> **提交阶段相当于2PC的`Commit`/`Rollback`阶段**

####  3PC的缺点

* 仍然可能存在脑裂：**试想协调者提交阶段发送`Commit`，有的节点收到了消息提交了事务，有的节点没有收到就没有提交事务，多个参与者之间仍然会数据不一致**

---

###  3.`Paxos`（超过半数）

核心：**超过半数**
> 即所谓的`Quorum`机制：  
**要求机器数量是奇数，每次需要有超过半数的机器ACK，操作方才会认为操作成功。**`ZK`集群用的就是这种方式。

####  `ZooKeeper`的`ZAB`协议

#####  崩溃恢复

* **`Leader`宕机，集群恢复后发现已有新`Leader`被选举出来，那么原`Leader`会变为新`Leader`的`Follower`，同步新的`Leader`**

---

###  4.`Raft`（日志复制、更多）

`Raft`是一种管理复制日志的分布式一致性算法。
> 参考自[http://ifeve.com/raft/](http://ifeve.com/raft/)

####  节点3种状态

![](https://dragonbaby308.oss-cn-hangzhou.aliyuncs.com/DS/raft%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81.jpeg)

每个节点有3个状态，可以相互切换（**选举流程**）：
1. `Leader`：主节点，**用于写数据**
2. `Candidate`：候选节点
3. `Follower`：从节点，**用于读数据**

#####  任期

每个`Leader`都有自己的**任期**：
1. **任期结束后如果没有新的`Candidate`参与选举，那么`Leader`可以连任**
2. **如果任期结束有新的`Candidate`参与选举，那么两者进行选举，选票更多的成为`Leader`**

#####  选举流程

![](https://dragonbaby308.oss-cn-hangzhou.aliyuncs.com/DS/raft%E9%80%89%E4%B8%BE%E6%B5%81%E7%A8%8B.png)

1. 节点状态初始都是`Follower`，**每个`Follower`会记录其`Leader`，然后和`Leader`之间维持一个心跳**
2. `Follower`100-300ms没有收到`Leader`的心跳回复，`Follower`就变成`Candidate`
3. `Candidate`给所有节点发送选票，获得**更多**`Follower`选票的`Candidate`就有资格成为`Leader`
4. **如果多个`Candidate`获得的票同样多，那么两个`Candidate`会重新发选票，直到票数较多的节点当选`Leader`**

####  日志复制流程

![](https://dragonbaby308.oss-cn-hangzhou.aliyuncs.com/DS/Raft%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6.jpeg)

1. **只有`Leader`才能接收客户端的写请求**
2. **每次`Leader`收到写请求，都会先记录日志**
3. **`Leader`将日志同步给所有`Follower`节点进行复制**
4. `Leader`等待**超过半数**的`Follower`节点写日志成功后才提交数据，反馈客户端提交成功

####  集群中断

当集群之间的部分节点失去通讯时，`Leader`的日志不能复制给多个`Follower`就不能进行提交。

####  崩溃恢复

1. 集群恢复后，如果`Leader`发现自己的**票数不是最多的，就会变成`Follower`，并回滚自己的日志**
2. **最后`Leader`会将自己的日志同步给所有`Follower`，保证主从数据一致性**

> `Raft`和`Paxos`崩溃恢复的区别：  
①`Paxos`的集群恢复是原`Leader`无论如何都变成新`Leader`的`Follower`；  
②而`Raft`不同于`Paxos`，集群恢复后原`Leader`不是直接变为`Follower`，而是**和新`Leader`进行比较，票更多的才当选新`Leader`**

